{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5745e41",
   "metadata": {},
   "source": [
    "\n",
    "# Reproducing Thennakoon et al. (2019): Credit‑Card Fraud Detection Methodology\n",
    "\n",
    "This notebook implements the **methodology** from *Thennakoon et al., 2019 — “Real-time Credit Card Fraud Detection Using Machine Learning”*:\n",
    "- Two preparation modes (**Type A numeric**, **Type B categorical**)\n",
    "- **Data cleaning, normalization**, and **PCA** for dimension reduction\n",
    "- **Class-imbalance handling** via **SMOTE**, **Random Under‑Sampling (RUS)**, **Condensed Nearest Neighbour (CNN)**\n",
    "- **10‑fold cross‑validation**\n",
    "- Classifiers: **SVM**, **Naïve Bayes**, **K‑Nearest Neighbors**, **Logistic Regression**\n",
    "- Metrics: **Accuracy, Precision, Recall, TPR, FPR, F1, ROC‑AUC, MCC**\n",
    "- (Optional) **Real‑time scoring stub**\n",
    "\n",
    "> Paper citation (uploaded): fileciteturn1file0\n",
    "\n",
    "> **Dataset note**: The paper’s four fraud patterns use fields like MCC, ISO response code, and URL. If those are **not** present in your dataset (e.g., Taiwan UCI credit default data), the notebook still reproduces the **learning pipeline** on the available target and features. Where the specific fields exist, the same pipeline can be applied **per fraud pattern**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install -q numpy pandas scikit-learn imbalanced-learn matplotlib seaborn\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, matthews_corrcoef, confusion_matrix, RocCurveDisplay\n",
    ")\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, CondensedNearestNeighbour\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 1200)\n",
    "\n",
    "SEED = 42\n",
    "RNG = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CSV_PATH = \"/mnt/data/Taiwan_UCI_Credit_Card.csv\"\n",
    "assert Path(CSV_PATH).exists(), f\"CSV not found at {CSV_PATH}\"\n",
    "\n",
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(df_raw.shape)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ecfa5",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset target & schema\n",
    "- If present, the canonical UCI Taiwan target is **`default.payment.next.month`** (1=default, 0=non‑default).\n",
    "- We will detect the target column automatically if possible; otherwise set it manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ca57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "candidate_targets = [\n",
    "    \"default.payment.next.month\", \"DEFAULT_NEXT_MONTH\", \"default_next_month\", \"target\", \"label\"\n",
    "]\n",
    "target_col = None\n",
    "for c in candidate_targets:\n",
    "    if c in df_raw.columns:\n",
    "        target_col = c\n",
    "        break\n",
    "print(\"Detected target:\", target_col)\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Could not detect target column. Please set `target_col` manually.\")\n",
    "\n",
    "df = df_raw.drop_duplicates().copy()\n",
    "if \"ID\" in df.columns:\n",
    "    df = df.drop(columns=[\"ID\"])\n",
    "\n",
    "print(\"Class balance:\\n\", df[target_col].value_counts(normalize=True).round(3))\n",
    "print(\"Nulls (top):\\n\", df.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a43f53",
   "metadata": {},
   "source": [
    "\n",
    "## Type A vs Type B Preparation\n",
    "- **Type A**: Numeric transform (+ standardization), optional **PCA**.\n",
    "- **Type B**: Keep numeric as-is, one‑hot encode categoricals; no numeric scaling beyond encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and c != target_col]\n",
    "cat_cols = [c for c in df.columns if (c != target_col) and (c not in num_cols)]\n",
    "print(\"Numeric columns (sample):\", num_cols[:10])\n",
    "print(\"Categorical columns (sample):\", cat_cols[:10])\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int).values\n",
    "\n",
    "typeA_preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), cat_cols) if cat_cols else (\"noop\",\"passthrough\",[]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "USE_PCA = True\n",
    "PCA_COMPONENTS = 0.95  # variance retained\n",
    "\n",
    "typeB_preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), cat_cols) if cat_cols else (\"noop\",\"passthrough\",[]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7869ae6",
   "metadata": {},
   "source": [
    "\n",
    "## Class Imbalance Handling & Models\n",
    "Resamplers: **SMOTE**, **RUS**, **CNN**.  \n",
    "Models: **LR**, **NB**, **KNN**, **SVM**.  \n",
    "Metrics include Accuracy, Precision/Recall/F1, ROC‑AUC, **MCC**, **TPR**, **FPR**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ef1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(max_iter=200, n_jobs=None, random_state=SEED),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=15, weights=\"distance\"),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=SEED),\n",
    "}\n",
    "\n",
    "def tpr_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp / (tp + fn) if (tp + fn) else 0.0\n",
    "\n",
    "def fpr_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return fp / (fp + tn) if (fp + tn) else 0.0\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "scorers = {\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "    \"f1\": make_scorer(f1_score, zero_division=0),\n",
    "    \"roc_auc\": make_scorer(roc_auc_score, needs_proba=True),\n",
    "    \"mcc\": make_scorer(matthews_corrcoef),\n",
    "    \"tpr\": make_scorer(tpr_score),\n",
    "    \"fpr\": make_scorer(fpr_score),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "def run_experiment(view_name:str, preprocessor, resampler, use_pca:bool):\n",
    "    steps = [(\"prep\", preprocessor)]\n",
    "    if use_pca:\n",
    "        steps += [(\"pca\", PCA(n_components=PCA_COMPONENTS, random_state=SEED))]\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for model_key, clf in models.items():\n",
    "        pipe_cls = ImbPipeline(steps=[(\"resample\", resampler)] + steps + [(\"model\", clf)])\n",
    "        cv = cross_validate(\n",
    "            pipe_cls, X, y, cv=skf, scoring=scorers, n_jobs=-1, return_train_score=False\n",
    "        )\n",
    "        row = {m: float(np.mean(cv[\"test_\"+m])) for m in scorers.keys()}\n",
    "        row.update(dict(view=view_name, resampler=type(resampler).__name__, model=model_key))\n",
    "        results.append(row)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bed8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "views = {\n",
    "    \"TypeA_numeric\": typeA_preprocess,\n",
    "    \"TypeB_categorical\": typeB_preprocess,\n",
    "}\n",
    "\n",
    "resamplers = [\n",
    "    SMOTE(random_state=SEED),\n",
    "    RandomUnderSampler(random_state=SEED),\n",
    "    CondensedNearestNeighbour(random_state=SEED),\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "for vname, prep in views.items():\n",
    "    for res in resamplers:\n",
    "        df_res = run_experiment(vname, prep, res, USE_PCA if vname==\"TypeA_numeric\" else False)\n",
    "        all_results.append(df_res)\n",
    "\n",
    "df_results = pd.concat(all_results, ignore_index=True)\n",
    "df_results_sorted = df_results.sort_values([\"roc_auc\",\"f1\",\"accuracy\"], ascending=False)\n",
    "display(df_results_sorted.head(20))\n",
    "\n",
    "OUT_DIR = Path(\"./outputs\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "df_results_sorted.to_csv(OUT_DIR / \"thennakoon2019_results.csv\", index=False)\n",
    "print(\"Saved results to:\", (OUT_DIR / \"thennakoon2019_results.csv\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dedb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_by_model = (\n",
    "    df_results_sorted\n",
    "    .groupby([\"view\",\"resampler\",\"model\"], as_index=False)\n",
    "    .head(1)\n",
    "    .sort_values([\"roc_auc\",\"f1\",\"accuracy\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(\"=== Best per (view, resampler, model) ===\")\n",
    "display(best_by_model.head(12))\n",
    "best_by_model.to_csv(OUT_DIR / \"thennakoon2019_best_by_model.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "top = df_results_sorted.iloc[0]\n",
    "print(top)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "(train_idx, test_idx) = next(iter(skf.split(X, y)))\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "prep = views[top['view']]\n",
    "pca_steps = [(\"pca\", PCA(n_components=PCA_COMPONENTS, random_state=SEED))] if top['view']==\"TypeA_numeric\" else []\n",
    "\n",
    "if top['resampler'] == \"SMOTE\":\n",
    "    resampler = SMOTE(random_state=SEED)\n",
    "elif top['resampler'] == \"RandomUnderSampler\":\n",
    "    resampler = RandomUnderSampler(random_state=SEED)\n",
    "else:\n",
    "    resampler = CondensedNearestNeighbour(random_state=SEED)\n",
    "\n",
    "clf = models[top['model']]\n",
    "pipe = ImbPipeline(steps=[(\"resample\", resampler), (\"prep\", prep)] + pca_steps + [(\"model\", clf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "if hasattr(clf, \"predict_proba\"):\n",
    "    y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    RocCurveDisplay.from_predictions(y_test, y_prob)\n",
    "    plt.title(f\"ROC — {top['model']} | {top['view']} | {top['resampler']}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model lacks predict_proba; skipping ROC.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491602b",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) Real‑time Scoring Stub\n",
    "The paper deploys models behind an API. Below simulates a basic request‑response with the **best** pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8dbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_best_pipeline(summary_row: pd.Series):\n",
    "    prep = views[summary_row['view']]\n",
    "    pca_steps = [(\"pca\", PCA(n_components=PCA_COMPONENTS, random_state=SEED))] if summary_row['view']==\"TypeA_numeric\" else []\n",
    "\n",
    "    if summary_row['resampler'] == \"SMOTE\":\n",
    "        resampler = SMOTE(random_state=SEED)\n",
    "    elif summary_row['resampler'] == \"RandomUnderSampler\":\n",
    "        resampler = RandomUnderSampler(random_state=SEED)\n",
    "    else:\n",
    "        resampler = CondensedNearestNeighbour(random_state=SEED)\n",
    "\n",
    "    clf = models[summary_row['model']]\n",
    "    return ImbPipeline(steps=[(\"resample\", resampler), (\"prep\", prep)] + pca_steps + [(\"model\", clf)])\n",
    "\n",
    "best_pipe = build_best_pipeline(df_results_sorted.iloc[0])\n",
    "best_pipe.fit(X, y)\n",
    "\n",
    "def score_transaction(json_like: dict) -> float:\n",
    "    row_df = pd.DataFrame([json_like])\n",
    "    for c in X.columns:\n",
    "        if c not in row_df.columns:\n",
    "            row_df[c] = np.nan\n",
    "    row_df = row_df[X.columns]\n",
    "    if hasattr(best_pipe.named_steps[\"model\"], \"predict_proba\"):\n",
    "        prob = best_pipe.predict_proba(row_df)[:,1][0]\n",
    "        return float(prob)\n",
    "    else:\n",
    "        pred = best_pipe.predict(row_df)[0]\n",
    "        return float(pred)\n",
    "\n",
    "print(\"Fraud score (example):\", score_transaction(X.iloc[0].to_dict()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1aa92",
   "metadata": {},
   "source": [
    "\n",
    "### Mapping the Paper’s Four Fraud Patterns\n",
    "If your data include **MCC**, **ISO response codes**, **URL**, or **amount** thresholds, create boolean masks to isolate each fraud pattern and run the same pipeline on each subset. Without those fields, you still reproduce the learning method (resampling + models + CV + metrics) on your available target.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
